{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics  # 데이터 셋 분류 YOLO 방식\n",
        "!pip install torchmetrics # mAP 함수 구하는 메트릭스\n",
        "!apt-get -qq install fonts-nanum # 시각화시 한글 깨짐으로 추가한 나눔고딕체"
      ],
      "metadata": {
        "id": "nIWV18rUnF-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라이브러리"
      ],
      "metadata": {
        "id": "Canj7YGTnT40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.font_manager as fm\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "prop = fm.FontProperties(fname=font_path, size=14)"
      ],
      "metadata": {
        "id": "Z78OSvw5qIef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zI7rKv6nE5M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from shutil import copy2\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.font_manager')\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정 (사용자 맞춤 절대 경로)\n",
        "ANNOTATIONS_DIR = Path(\"/content/drive/MyDrive/first_project/train_annotations\") # 원본\n",
        "IMAGES_DIR = Path(\"/content/drive/MyDrive/first_project/train_images\") # 원본\n",
        "OUTPUT_LABELS  = Path(\"/content/drive/MyDrive/first_project/labels\") # 수정한 레벨 데이터 경로\n",
        "OUTPUT_LABELS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/first_project/project_yolo\")\n",
        "IMAGE_TRAIN = OUTPUT_DIR / \"images\" / \"train\" # / img\n",
        "IMAGE_VAL   = OUTPUT_DIR / \"images\" / \"val\"\n",
        "LABEL_TRAIN = OUTPUT_DIR / \"labels\" / \"train\"\n",
        "LABEL_VAL   = OUTPUT_DIR / \"labels\" / \"val\"\n",
        "VAL_RATIO = 0.2"
      ],
      "metadata": {
        "id": "MRXStKjgn04a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리\n",
        "데이터 분류<br>\n",
        "기존 코드의 전처리 결과 라벨 파일의 txt 내용이 알약 라벨링 , 바운딩박스 좌표 형태의 1줄 만 존재 <br>\n",
        "하나의 이미지에 여러 알약이 존재하여 1줄형태가 아닌 이미지에 해당하는 모든 정보 통합으로 변경"
      ],
      "metadata": {
        "id": "kUDTsz_TnWKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for d in [IMAGE_TRAIN, IMAGE_VAL, LABEL_TRAIN, LABEL_VAL]:           # 라벨을 평가데이터와 학습 데이터로 나눔 8 : 2\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 전체 이미지 목록\n",
        "all_images = list(IMAGES_DIR.glob(\"*.png\"))\n",
        "random.shuffle(all_images)\n",
        "\n",
        "VAL_RATIO = 0.2  # 20% validation\n",
        "val_cnt = int(len(all_images) * VAL_RATIO)\n",
        "\n",
        "val_images = set(all_images[:val_cnt])\n",
        "train_images = set(all_images[val_cnt:])\n",
        "\n",
        "# 함수: 이미지와 라벨 쌍 복사\n",
        "def copy_dataset(image_list, img_dst_dir, label_dst_dir):\n",
        "    for img_path in image_list:\n",
        "        label_path = OUTPUT_LABELS / (img_path.stem + \".txt\")\n",
        "        copy2(img_path, img_dst_dir / img_path.name)\n",
        "        if label_path.exists():\n",
        "            copy2(label_path, label_dst_dir / label_path.name)\n",
        "        else:\n",
        "            # 라벨 없는 이미지면 빈 파일로 생성해도 됨 (선택)\n",
        "            open(label_dst_dir / label_path.name, 'w').close()\n",
        "\n",
        "copy_dataset(train_images, IMAGE_TRAIN, LABEL_TRAIN)\n",
        "copy_dataset(val_images, IMAGE_VAL, LABEL_VAL)\n",
        "\n",
        "print(f\"Train images: {len(train_images)} | Val images: {len(val_images)}\")"
      ],
      "metadata": {
        "id": "H7dmaiWMnscP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 함수 및 변수"
      ],
      "metadata": {
        "id": "MatMHTjNoibk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_index= {0: 0, 1899: 1, 2482: 2, 3350: 3, 3482: 4, 3543: 5, 3742: 6, 3831: 7, 4377: 8, 4542: 9, 5093: 10, 5885: 11, 6191: 12, 6562: 13, 10220: 14, 12080: 15, 12246: 16, 12419: 17, 12777: 18, 13394: 19, 13899: 20, 16231: 21, 16261: 22, 16547: 23, 16550: 24, 16687: 25, 18109: 26, 18146: 27, 18356: 28, 19231: 29, 19551: 30, 19606: 31, 19860: 32, 20013: 33, 20237: 34, 20876: 35, 21025: 36, 21324: 37, 21770: 38, 22073: 39, 22346: 40, 22361: 41, 22626: 42, 23202: 43, 23222: 44, 24849: 45, 25366: 46, 25437: 47, 25468: 48, 27652: 49, 27732: 50, 27776: 51, 27925: 52, 27992: 53, 28762: 54, 29344: 55, 29450: 56, 29666: 57, 29870: 58, 30307: 59, 31704: 60, 31862: 61, 31884: 62, 32309: 63, 33008: 64, 33207: 65, 33877: 66, 33879: 67, 34596: 68, 35205: 69, 36636: 70, 38161: 71, 41767: 72, 44198: 73, 10223: 74}\n",
        "index_to_name= {0: 'background', 1: '보령부스파정 5mg', 2: '뮤테란캡슐 100mg', 3: '일양하이트린정 2mg', 4: '기넥신에프정(은행엽엑스)(수출용)', 5: '무코스타정(레바미피드)(비매품)', 6: '알드린정', 7: '뉴로메드정(옥시라세탐)', 8: '타이레놀정500mg', 9: '에어탈정(아세클로페낙)', 10: '삼남건조수산화알루미늄겔정', 11: '타이레놀이알서방정(아세트아미노펜)(수출용)', 12: '삐콤씨에프정 618.6mg/병', 13: '조인스정 200mg', 14: '쎄로켈정 100mg', 15: '리렉스펜정 300mg/PTP', 16: '아빌리파이정 10mg', 17: '자이프렉사정 2.5mg', 18: '다보타민큐정 10mg/병', 19: '써스펜8시간이알서방정 650mg', 20: '에빅사정(메만틴염산염)(비매품)', 21: '리피토정 20mg', 22: '크레스토정 20mg', 23: '가바토파정 100mg', 24: '동아가바펜틴정 800mg', 25: '오마코연질캡슐(오메가-3-산에틸에스테르90)', 26: '란스톤엘에프디티정 30mg', 27: '리리카캡슐 150mg', 28: '종근당글리아티린연질캡슐(콜린알포세레이트)\\xa0', 29: '콜리네이트연질캡슐 400mg', 30: '트루비타정 60mg/병', 31: '스토가정 10mg', 32: '노바스크정 5mg', 33: '마도파정', 34: '플라빅스정 75mg', 35: '엑스포지정 5/160mg', 36: '펠루비정(펠루비프로펜)', 37: '아토르바정 10mg', 38: '라비에트정 20mg', 39: '리피로우정 20mg', 40: '자누비아정 50mg', 41: '맥시부펜이알정 300mg', 42: '메가파워정 90mg/병', 43: '쿠에타핀정 25mg', 44: '비타비백정 100mg/병', 45: '놀텍정 10mg', 46: '자누메트정 50/850mg', 47: '큐시드정 31.5mg/PTP', 48: '아모잘탄정 5/100mg', 49: '세비카정 10/40mg', 50: '트윈스타정 40/5mg', 51: '카나브정 60mg', 52: '울트라셋이알서방정', 53: '졸로푸트정 100mg', 54: '트라젠타정(리나글립틴)', 55: '비모보정 500/20mg', 56: '레일라정', 57: '리바로정 4mg', 58: '렉사프로정 15mg', 59: '트라젠타듀오정 2.5/850mg', 60: '낙소졸정 500/20mg', 61: '아질렉트정(라사길린메실산염)', 62: '자누메트엑스알서방정 100/1000mg', 63: '글리아타민연질캡슐', 64: '신바로정', 65: '에스원엠프정 20mg', 66: '브린텔릭스정 20mg', 67: '글리틴정(콜린알포세레이트)', 68: '제미메트서방정 50/1000mg', 69: '아토젯정 10/40mg', 70: '로수젯정10/5밀리그램', 71: '로수바미브정 10/20mg', 72: '카발린캡슐 25mg', 73: '케이캡정 50mg', 74: \"넥시움정 40mg\"}"
      ],
      "metadata": {
        "id": "uJotzAgsoft7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_multiple_predictions(dataset, model, class_names, num_images=12, score_threshold=0.5):  # 이미지 출력 코드 12개의 이미지로 num_images 입력값을 변경해서 이미지를 추가로 더뽑을 수 있음\n",
        "  idxs = random.sample(range(len(dataset)), k=num_images)\n",
        "  ncols = 3\n",
        "  nrows = 4\n",
        "  fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n",
        "\n",
        "  for ax, sample_idx in zip(axes.flatten(), idxs):\n",
        "      img, _ = dataset[sample_idx]\n",
        "      with torch.no_grad():\n",
        "          output = model([img.to(device)])[0]\n",
        "      npimg = (img.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8).copy()\n",
        "      ax.imshow(npimg)\n",
        "      h, w = npimg.shape[:2]\n",
        "      boxes = output['boxes'].cpu().numpy()\n",
        "      labels = output['labels'].cpu().numpy()\n",
        "      scores = output['scores'].cpu().numpy()\n",
        "      for box, label, score in zip(boxes, labels, scores):\n",
        "          if score < score_threshold:\n",
        "              continue\n",
        "          x1, y1, x2, y2 = map(int, box)\n",
        "          rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='red', linewidth=2)\n",
        "          ax.add_patch(rect)\n",
        "          txt = f\"{class_names[label]}:{score:.2f}\"\n",
        "          ax.text(x1, y1-5, txt, fontsize=12, color='blue',\n",
        "                  fontproperties=prop,\n",
        "                  bbox=dict(facecolor='white', alpha=0.7, boxstyle='round'))\n",
        "      ax.set_axis_off()\n",
        "      ax.set_title(f\"샘플 {sample_idx}\", fontproperties=prop)\n",
        "  # 빈 ax가 남으면 지우기\n",
        "  for ax in axes.flatten()[len(idxs):]:\n",
        "      ax.remove()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8YFRUWypofsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_test_predictions(dataset, model, class_names, device, num_images=12, score_threshold=0.5): # 테스트 이미지 시각화\n",
        "    idxs = random.sample(range(len(dataset)), k=min(num_images, len(dataset)))\n",
        "    ncols = 3\n",
        "    nrows = int(np.ceil(num_images / ncols))\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n",
        "\n",
        "    axes = axes.flatten() if num_images > 1 else [axes]\n",
        "\n",
        "    for ax, sample_idx in zip(axes, idxs):\n",
        "        img, fname = dataset[sample_idx]\n",
        "        input_img = img.unsqueeze(0) if img.ndim == 3 else img\n",
        "        with torch.no_grad():\n",
        "            output = model(input_img.to(device))[0]\n",
        "        # img: (C, H, W)\n",
        "        npimg = (img.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)\n",
        "        ax.imshow(npimg)\n",
        "        boxes = output['boxes'].cpu().numpy()\n",
        "        labels = output['labels'].cpu().numpy()\n",
        "        scores = output['scores'].cpu().numpy()\n",
        "        h, w = npimg.shape[:2]\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            if score < score_threshold:\n",
        "                continue\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='red', linewidth=2)\n",
        "            ax.add_patch(rect)\n",
        "            # 클래스명이 숫자 리스트인 경우 안전 처리\n",
        "            label_str = class_names[label] if label < len(class_names) else str(label)\n",
        "            txt = f\"{label_str}:{score:.2f}\"\n",
        "            ax.text(x1, max(y1-5, 0), txt, fontsize=12, color='blue',\n",
        "                    fontproperties=prop if prop else None,\n",
        "                    bbox=dict(facecolor='white', alpha=0.7, boxstyle='round'))\n",
        "        ax.set_axis_off()\n",
        "        ax.set_title(f\"{fname}\", fontproperties=prop if prop else None)\n",
        "    # 남은 빈 ax 지우기\n",
        "    for ax in axes[len(idxs):]:\n",
        "        ax.remove()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Vuc-htPSQ82n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelDataset(Dataset):                                # 라벨에 여러 데이터가 있는 경우의 데이터셋\n",
        "    def __init__(self, img_dir, label_dir, transforms=None):\n",
        "        self.img_paths = sorted(list(Path(img_dir).glob(\"*.png\")))\n",
        "        self.label_dir = Path(label_dir)\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        # 라벨 읽기\n",
        "        label_path = self.label_dir / (img_path.stem + \".txt\")\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        if label_path.exists():\n",
        "            with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                for line in f:\n",
        "                    splits = line.strip().split()\n",
        "                    if len(splits) != 5:\n",
        "                        continue\n",
        "                    class_id = int(splits[0])\n",
        "                    x_c, y_c, bw, bh = map(float, splits[1:])\n",
        "                    x1 = (x_c - bw/2) * w\n",
        "                    y1 = (y_c - bh/2) * h\n",
        "                    x2 = (x_c + bw/2) * w\n",
        "                    y2 = (y_c + bh/2) * h\n",
        "                    boxes.append([x1, y1, x2, y2])\n",
        "                    labels.append(class_id)\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,4), dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64) if labels else torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels\n",
        "        }\n",
        "        img = torch.from_numpy(img).permute(2,0,1).float() / 255.\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "        return img, target"
      ],
      "metadata": {
        "id": "jd_5nVQNRFaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_list = [f for f in os.listdir(image_dir)\n",
        "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_list[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.image_list[idx]  # (이미지, 파일명)"
      ],
      "metadata": {
        "id": "iiYHcSaKRISp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions_to_csv(dataset, model, id_to_index, device, out_csv_path, score_threshold=0.5):\n",
        "    results = []\n",
        "    annotation_id = 1\n",
        "    class_mapping = {v: k for k, v in id_to_index.items()}\n",
        "    for idx in range(len(dataset)):\n",
        "        img, fname = dataset[idx]\n",
        "        input_img = img.unsqueeze(0) if isinstance(img, torch.Tensor) and img.ndim == 3 else img\n",
        "        with torch.no_grad():\n",
        "            output = model(input_img.to(device))[0]\n",
        "        boxes = output['boxes'].cpu().numpy()\n",
        "        labels = output['labels'].cpu().numpy()\n",
        "        scores = output['scores'].cpu().numpy()\n",
        "\n",
        "        # image_id는 파일명에서 확장자 제거한 부분을 int로 변환\n",
        "        image_id = int(os.path.splitext(fname)[0])\n",
        "\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            if score < score_threshold:\n",
        "                continue\n",
        "            x1, y1, x2, y2 = box\n",
        "            bbox_x, bbox_y = int(x1), int(y1)\n",
        "            bbox_w, bbox_h = int(x2 - x1), int(y2 - y1)\n",
        "            if label not in class_mapping:  # 74번(혹은 없는 라벨) 스킵\n",
        "                continue\n",
        "            category_id = class_mapping[int(label)]\n",
        "            row = [\n",
        "                annotation_id,\n",
        "                image_id,\n",
        "                category_id,\n",
        "                bbox_x, bbox_y, bbox_w, bbox_h,\n",
        "                round(float(score), 2)\n",
        "            ]\n",
        "            results.append(row)\n",
        "            annotation_id += 1\n",
        "\n",
        "    header = ['annotation_id', 'image_id', 'category_id', 'bbox_x', 'bbox_y', 'bbox_w', 'bbox_h', 'score']\n",
        "    with open(out_csv_path, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(header)\n",
        "        writer.writerows(results)"
      ],
      "metadata": {
        "id": "6GycgAxbI0Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델"
      ],
      "metadata": {
        "id": "1GQNHM0yo0Zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Faster R-CNN 모델 생성 함수\n",
        "def model_resnet50_fpn_v1(num_classes: int):\n",
        "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "-kgZYWKGoyCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_resnet50_fpn_v2(num_classes: int):\n",
        "    model = models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "h4msceWXzcQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_resnet101_fpn(num_classes: int):\n",
        "    backbone = models.detection.backbone_utils.resnet_fpn_backbone(\n",
        "        'resnet101',\n",
        "        pretrained=True,\n",
        "        norm_layer= nn.BatchNorm2d\n",
        "    )\n",
        "\n",
        "    model = models.detection.FasterRCNN(backbone, num_classes=num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "wvhS7bRwzgBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0.0, std=0.1):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        noise = torch.randn(tensor.size()) * self.std + self.mean\n",
        "        return tensor + noise"
      ],
      "metadata": {
        "id": "w_Bw74V35f0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomApply([AddGaussianNoise(0., 0.1)], p=0.5),\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "lca9NVfw5iHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 및 클래스 수 지정\n",
        "train_img_dir = \"/content/drive/MyDrive/first_project/project_yolo/images/train\"\n",
        "train_label_dir = \"/content/drive/MyDrive/first_project/project_yolo/labels/train\"\n",
        "val_img_dir = \"/content/drive/MyDrive/first_project/project_yolo/images/val\"\n",
        "val_label_dir = \"/content/drive/MyDrive/first_project/project_yolo/labels/val\"\n",
        "test_img_dir = \"/content/drive/MyDrive/first_project/test_images\"                   # 원본테스트 이미지 경로\n",
        "\n",
        "# index_to_name은 {0:'background', 1:'알약1', ...} 형식\n",
        "num_classes = len(index_to_name)  # background 포함\n",
        "\n",
        "# 데이터셋, 로더\n",
        "train_dataset = LabelDataset1(train_img_dir, train_label_dir, transforms= transform)\n",
        "val_dataset = LabelDataset1(val_img_dir, val_label_dir, transforms= None)\n",
        "test_dataset = TestImageDataset(test_img_dir, transform= transform_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
      ],
      "metadata": {
        "id": "LljqqQGpo1lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model_resnet50_fpn_v2(num_classes)  # 모델 종류에 따라 변경\n",
        "model.to(device)\n",
        "optimizer = torch.optim.SGD([p for p in model.parameters() if p.requires_grad], lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "metadata": {
        "id": "NS6rgCuEo1iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습"
      ],
      "metadata": {
        "id": "SZuV2jHX8PBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "accumulation_steps = 8 # 배치사이즈 증가를 위한 step 방식 배치사이즈의 곱으로 작용 4배치에 8스텝이라 32배치와 유사하게 작동\n",
        "# 학습\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    optimizer.zero_grad()  # 에폭 시작 시 초기화\n",
        "\n",
        "    for i, (images, targets) in enumerate(train_loader):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        # loss를 나눠 역전파가 스텝회수만큼 반복\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "        running_loss += loss.item() * accumulation_steps  # 누적 시 원래 loss 기준으로\n",
        "\n",
        "        # 누적 스텝마다 optimizer.step()\n",
        "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        del loss_dict, loss       #코랩 메모리 절약을 위한 캐시 삭제\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    lr_scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.eval()\n",
        "        metric = MeanAveragePrecision()\n",
        "        for images, targets in val_loader:\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            with torch.no_grad():\n",
        "                preds = model(images)\n",
        "                metric.update(preds, targets)\n",
        "        mAP = metric.compute()[\"map\"].item()\n",
        "        print(f\"[Validation] Epoch {epoch+1}: mAP={mAP:.4f} Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "        images, targets = next(iter(val_loader))\n",
        "        images = [img.to(device) for img in images]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        for i in range(min(2, len(images))):\n",
        "            plot_prediction(images[i].cpu(), outputs[i], threshold=0.5)\n",
        "        model.train()"
      ],
      "metadata": {
        "id": "FMZlDczTo1dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 저장\n",
        "torch.save(model.state_dict(), \"fasterrcnn_model_R10.pth\")"
      ],
      "metadata": {
        "id": "GlVF1L7Lp1qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 가중치 불러오기\n",
        "model.load_state_dict(torch.load(\"fasterrcnn_model_R10.pth\"))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "bFSHSqA9pxDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 중간 저장\n",
        "torch.save({\n",
        "    'model': model.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "    'scheduler': lr_scheduler.state_dict(),\n",
        "    'epoch': num_epochs,\n",
        "}, 'v2+noise0.1+30.pth')"
      ],
      "metadata": {
        "id": "2d7ufc4d6RHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 중간 저장 복구\n",
        "checkpoint = torch.load('v2+noise0.1+30.pth')\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "lr_scheduler.load_state_dict(checkpoint['scheduler'])  # 이전 상태가 그대로 복구됨\n",
        "start_epoch = checkpoint['epoch'] + 1"
      ],
      "metadata": {
        "id": "_Wy-8tby6S9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 시각화"
      ],
      "metadata": {
        "id": "5iIGtZfUp5_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "class_names = [index_to_name[i] for i in range(len(index_to_name))]\n",
        "show_multiple_predictions(val_dataset, model, class_names, num_images=10, score_threshold=0.5) # val_data로 시각화"
      ],
      "metadata": {
        "id": "Zxu202CCp5xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "class_names = [index_to_name[i] for i in range(len(index_to_name))]\n",
        "show_test_predictions(test_dataset, model, class_names, device, num_images=12, score_threshold=0.5) # test_data로 시각화"
      ],
      "metadata": {
        "id": "7uXSi2UTRejF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 성능 지표"
      ],
      "metadata": {
        "id": "KdP2m83K7KNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mAP 객체 생성 test 데이터는 라벨이 없어서 출력 불가능\n",
        "map_metric = MeanAveragePrecision(iou_type=\"bbox\")  # 기본은 COCO mAP@[.5:.95]\n",
        "\n",
        "model.eval()\n",
        "device = next(model.parameters()).device\n",
        "\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "for img, target in val_dataset:\n",
        "    with torch.no_grad():\n",
        "        pred = model([img.to(device)])[0]\n",
        "    if len(target['labels']) == 0:   # GT 없음\n",
        "        continue                     # 평가에서 스킵\n",
        "    # 예측 박스\n",
        "    preds = {\n",
        "        \"boxes\": pred['boxes'].cpu(),\n",
        "        \"scores\": pred['scores'].cpu(),\n",
        "        \"labels\": pred['labels'].cpu()\n",
        "    }\n",
        "    # GT(정답) 박스\n",
        "    targets = {\n",
        "        \"boxes\": target['boxes'],\n",
        "        \"labels\": target['labels']\n",
        "    }\n",
        "    map_metric.update([preds], [targets])  # 리스트 형태\n",
        "\n",
        "# mAP, AP50 등 리포트\n",
        "result = map_metric.compute()\n",
        "print(\"mAP:\", result['map'].item()) # 50~95\n",
        "print(\"mAP@0.5:\", result['map_50'].item())\n",
        "print(\"mAP@0.75:\", result['map_75'].item())"
      ],
      "metadata": {
        "id": "qfndcJ5zp5zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(box1, box2):\n",
        "    \"\"\"box: [x1, y1, x2, y2]\"\"\"\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    if union_area == 0:\n",
        "        return 0\n",
        "    return inter_area / union_area"
      ],
      "metadata": {
        "id": "K6cvLaD-7Nj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp_per_class = np.zeros(num_classes)\n",
        "fp_per_class = np.zeros(num_classes)\n",
        "gt_per_class = np.zeros(num_classes)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        outputs = model(images)\n",
        "        for output, target in zip(outputs, targets):\n",
        "            pred_boxes = output['boxes'].cpu().numpy()\n",
        "            pred_labels = output['labels'].cpu().numpy()\n",
        "            true_boxes = target['boxes'].cpu().numpy()\n",
        "            true_labels = target['labels'].cpu().numpy()\n",
        "\n",
        "            gt_matched = set()\n",
        "            for pbox, plabel in zip(pred_boxes, pred_labels):\n",
        "                match = False\n",
        "                for i, (gt_box, gt_label) in enumerate(zip(true_boxes, true_labels)):\n",
        "                    if i in gt_matched:\n",
        "                        continue\n",
        "                    if plabel == gt_label and compute_iou(pbox, gt_box) >= 0.5:\n",
        "                        tp_per_class[plabel] += 1\n",
        "                        gt_matched.add(i)\n",
        "                        match = True\n",
        "                        break\n",
        "                if not match:\n",
        "                    fp_per_class[plabel] += 1\n",
        "            # 정답 개수 누적\n",
        "            for gt_label in true_labels:\n",
        "                gt_per_class[gt_label] += 1\n",
        "\n",
        "precision_per_class = tp_per_class / (tp_per_class + fp_per_class + 1e-8)\n",
        "recall_per_class = tp_per_class / (gt_per_class + 1e-8)"
      ],
      "metadata": {
        "id": "w3tltxxQ7NiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [f\"Class {i}\" for i in range(1, num_classes)]  # 혹은 실제 클래스 이름 리스트\n",
        "\n",
        "# 100% 적중(precision=1, recall=1) 클래스 인덱스 추출\n",
        "exclude_idx = [i for i in range(1, num_classes)\n",
        "               if np.isclose(precision_per_class[i], 1.0) and np.isclose(recall_per_class[i], 1.0)]\n",
        "\n",
        "# 100% 적중 클래스 제외한 인덱스만 추출\n",
        "include_idx = [i for i in range(1, num_classes) if i not in exclude_idx]\n",
        "\n",
        "# 필터링 추출된 인덱스 기준 제외\n",
        "filtered_classes = [classes[i] for i in include_idx]\n",
        "filtered_precision = [precision_per_class[i] for i in include_idx]\n",
        "filtered_recall = [recall_per_class[i] for i in include_idx]\n",
        "x = np.arange(len(filtered_classes))\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(x - 0.15, filtered_precision, width=0.3, label='Precision')\n",
        "# plt.bar(x + 0.15, filtered_recall, width=0.3, label='Recall')\n",
        "plt.xticks(x, filtered_classes, rotation=45)\n",
        "plt.ylim(0, 1.05)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Per-Class Precision (Exclude 100%) Record No.5 ')  # 코랩 한글 파일 문제로 영어로 작성\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "# Precision 값 표시\n",
        "for i, v in enumerate(filtered_precision):\n",
        "    plt.text(i - 0.15, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom', fontsize=9)\n",
        "# Recall 값 표시\n",
        "# for i, v in enumerate(filtered_recall):\n",
        "#     plt.text(i + 0.15, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom', fontsize=9) # 대부분의 모델이 재현률은 100%로 주석처리\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S251wj667Nfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### csv 파일 출력"
      ],
      "metadata": {
        "id": "nzXM76bznU4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_predictions_to_csv(test_dataset, model, id_to_index, device, 'submission.csv', score_threshold=0.5)"
      ],
      "metadata": {
        "id": "HNpH5t3qnhae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV 파일 두 개 불러오기\n",
        "df1 = pd.read_csv('submission_noise+6.2+30.csv')\n",
        "df2 = pd.read_csv('submission_resnet101+6.2+50.csv')\n",
        "\n",
        "# image_id별로 category_id를 묶기\n",
        "set1 = df1.groupby('image_id')['category_id'].apply(set)\n",
        "set2 = df2.groupby('image_id')['category_id'].apply(set)\n",
        "\n",
        "# 같은 image_id에서 category_id set이 다른 경우만 추출\n",
        "diff = []\n",
        "for img_id in set(set1.index).union(set2.index):\n",
        "    c1 = set1.get(img_id, set())\n",
        "    c2 = set2.get(img_id, set())\n",
        "    if c1 != c2:\n",
        "        diff.append((img_id, c1, c2))\n",
        "\n",
        "# 결과 출력\n",
        "for img_id, cats1, cats2 in diff:\n",
        "    print(f\"image_id: {img_id}\\n  file1: {cats1}\\n  file2: {cats2}\\n\") # 같은 이미지에서 다르게 분류한경우 어떻게 다르게 분류 했는지 출력"
      ],
      "metadata": {
        "id": "9TlfYYs86ycC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습 혹은 출력된 파일 다운로드"
      ],
      "metadata": {
        "id": "Xa5iozud7fRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('v2+noise0.1+30.pth') # 파일 명입력으로 실행 순서로 자동 다운로드"
      ],
      "metadata": {
        "id": "1vqsVybI6yZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p28X2zd_6yXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}